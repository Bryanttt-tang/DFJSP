import gymnasium as gym
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from gymnasium import spaces
import random
from stable_baselines3.common.vec_env import DummyVecEnv
from sb3_contrib import MaskablePPO
from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy
from sb3_contrib.common.maskable.utils import get_action_masks
from sb3_contrib.common.wrappers import ActionMasker
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.torch_layers import BaseFeaturesExtractor
import torch
import torch.nn as nn
import torch.nn.functional as F
import os
import collections
from pulp import LpProblem, LpMinimize, LpVariable, lpSum, PULP_CBC_CMD
import argparse
import importlib.util
import sys
import math
import time

# Set random seed for reproducibility
random.seed(42)
np.random.seed(42)

# --- Default Instance Data ---
# DEFAULT_JOBS_DATA = collections.OrderedDict({
#     0: [{'proc_times': {'M0': 5, 'M1': 7}}, {'proc_times': {'M1': 6, 'M2': 4}}, {'proc_times': {'M0': 3}}],
#     1: [{'proc_times': {'M1': 8, 'M2': 6}}, {'proc_times': {'M0': 5}}, {'proc_times': {'M1': 4, 'M2': 5}}],
#     2: [{'proc_times': {'M0': 6, 'M2': 7}}, {'proc_times': {'M0': 4, 'M1': 5}}, {'proc_times': {'M2': 8}}],
#     3: [{'proc_times': {'M1': 9}}, {'proc_times': {'M2': 3}}, {'proc_times': {'M0': 6, 'M1': 7}}]
# })
# DEFAULT_MACHINE_LIST = ['M0', 'M1', 'M2']
# DEFAULT_ARRIVAL_TIMES = {0: 0, 1: 0, 2: 10, 3: 15}

DEFAULT_JOBS_DATA = collections.OrderedDict({
    # Jobs ready at t=0
    0: [{'proc_times': {'M0': 6, 'M1': 8}}, {'proc_times': {'M1': 5, 'M2': 7}}, {'proc_times': {'M0': 4}}],
    1: [{'proc_times': {'M1': 7, 'M2': 5}}, {'proc_times': {'M0': 6}}, {'proc_times': {'M1': 8, 'M2': 4}}],
    2: [{'proc_times': {'M0': 5, 'M2': 9}}, {'proc_times': {'M0': 3, 'M1': 7}}, {'proc_times': {'M2': 6}}],
    
    # Job arriving at t=10
    3: [{'proc_times': {'M1': 4, 'M2': 8}}, {'proc_times': {'M0': 7, 'M1': 5}}, {'proc_times': {'M2': 9}}],
    
    # Job arriving at t=15
    4: [{'proc_times': {'M0': 8}}, {'proc_times': {'M1': 6, 'M2': 5}}, {'proc_times': {'M0': 7, 'M1': 4}}],
    
    # Job arriving at t=25
    5: [{'proc_times': {'M1': 9, 'M2': 6}}, {'proc_times': {'M0': 5}}, {'proc_times': {'M1': 3, 'M2': 8}}],
    
    # Job arriving at t=35
    6: [{'proc_times': {'M0': 6, 'M1': 7}}, {'proc_times': {'M2': 4}}, {'proc_times': {'M0': 8, 'M1': 5}}, {'proc_times': {'M2': 7}}]
})
DEFAULT_MACHINE_LIST = ['M0', 'M1', 'M2']
DEFAULT_ARRIVAL_TIMES = {0: 0, 1: 0, 2: 0, 3: 10, 4: 15, 5: 25, 6: 35}

# ...existing code...

def load_instance_from_file(filepath):
    """Load instance data from a Python file generated by possison.py"""
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"Instance file not found: {filepath}")
    
    try:
        # Method 1: Direct execution with exec()
        with open(filepath, 'r') as f:
            content = f.read()
        
        # Create a namespace to execute the file content
        namespace = {}
        exec(content, namespace)
        
        # Extract the required variables
        jobs_data = namespace.get('jobs_data', None)
        machine_list = namespace.get('machine_list', None)
        job_arrival_times = namespace.get('job_arrival_times', None)
        
        if jobs_data is None or machine_list is None or job_arrival_times is None:
            raise ValueError(f"Instance file {filepath} must contain 'jobs_data', 'machine_list', and 'job_arrival_times'")
        
        print(f"Loaded instance from {filepath}")
        print(f"Jobs: {len(jobs_data)}, Machines: {len(machine_list)}")
        print(f"Arrival times: {job_arrival_times}")
        
        return jobs_data, machine_list, job_arrival_times
        
    except Exception as e:
        print(f"Error reading file with exec method: {e}")
        
        # Method 2: Fallback to importlib (with better error handling)
        try:
            # Get absolute path
            abs_filepath = os.path.abspath(filepath)
            
            # Load the module dynamically
            spec = importlib.util.spec_from_file_location("instance_module", abs_filepath)
            
            if spec is None or spec.loader is None:
                raise ImportError(f"Could not create module spec for {abs_filepath}")
            
            instance_module = importlib.util.module_from_spec(spec)
            
            # Add to sys.modules to avoid import issues
            sys.modules["instance_module"] = instance_module
            
            spec.loader.exec_module(instance_module)
            
            # Extract the required variables
            jobs_data = getattr(instance_module, 'jobs_data', None)
            machine_list = getattr(instance_module, 'machine_list', None)
            job_arrival_times = getattr(instance_module, 'job_arrival_times', None)
            
            if jobs_data is None or machine_list is None or job_arrival_times is None:
                raise ValueError(f"Instance file {filepath} must contain 'jobs_data', 'machine_list', and 'job_arrival_times'")
            
            print(f"Loaded instance from {filepath}")
            print(f"Jobs: {len(jobs_data)}, Machines: {len(machine_list)}")
            print(f"Arrival times: {job_arrival_times}")
            
            return jobs_data, machine_list, job_arrival_times
            
        except Exception as e2:
            raise RuntimeError(f"Failed to load instance file {filepath}. Exec error: {e}, Import error: {e2}")

# --- 1. Gantt Chart Plotter ---
def plot_gantt(schedule, machines, title="Schedule"):
    """Plot Gantt chart for the schedule with A0 poster formatting"""
    # Set font configuration for A0 poster visibility
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 28,           # Increased base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility
        'axes.titlesize': 40,      # Much larger title
        'axes.labelsize': 36,      # Much larger axis labels
        'xtick.labelsize': 30,     # Much larger tick labels
        'ytick.labelsize': 30,     # Much larger tick labels
        'legend.fontsize': 26,     # Much larger legend
        'figure.titlesize': 44     # Much larger figure title
    })
    
    if not schedule or all(len(ops) == 0 for ops in schedule.values()):
        print("No schedule to plot - schedule is empty")
        return

    colors = plt.cm.tab20.colors
    fig, ax = plt.subplots(figsize=(28, len(machines) * 3.0))  # Much larger figure to prevent overlapping
    fig.patch.set_facecolor('white')

    for idx, m in enumerate(machines):
        machine_ops = schedule.get(m, [])
        machine_ops.sort(key=lambda x: x[1])

        for op_data in machine_ops:
            if len(op_data) == 3:
                job_id_str, start, end = op_data
                try:
                    # Extract job number from "J0-O1"
                    j = int(job_id_str.split('-')[0][1:])
                except (ValueError, IndexError):
                    j = hash(job_id_str) % len(colors)
                
                ax.broken_barh(
                    [(start, end - start)],
                    (idx * 10, 8),
                    facecolors=colors[j % len(colors)],
                    edgecolor='black',
                    alpha=0.8,
                    linewidth=2  # Thicker lines for poster visibility
                )
                label = job_id_str
                ax.text(start + (end - start) / 2, idx * 10 + 4,
                       label, color='white', fontsize=24,  # Larger text in bars
                       ha='center', va='center', weight='bold')

    ax.set_yticks([i * 10 + 4 for i in range(len(machines))])
    ax.set_yticklabels(machines)
    ax.set_xlabel("Time", fontsize=36, fontweight='bold')      # Increased label size
    ax.set_ylabel("Machines", fontsize=36, fontweight='bold')  # Increased label size
    ax.set_title(title, fontsize=40, fontweight='bold')        # Increased title size
    ax.grid(True, alpha=0.3, linewidth=1.5)
    plt.tight_layout()
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()

def plot_dynamic_rl_gantt(schedule, makespan, machine_list, arrival_times, save_path=None):
    """Plot Dynamic RL Gantt chart optimized for A0 poster with Segoe UI font."""
    # Set font configuration for A0 poster visibility
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 28,           # Increased base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility
        'axes.titlesize': 40,      # Much larger title
        'axes.labelsize': 36,      # Much larger axis labels
        'xtick.labelsize': 30,     # Much larger tick labels
        'ytick.labelsize': 30,     # Much larger tick labels
        'legend.fontsize': 26,     # Much larger legend
        'figure.titlesize': 44     # Much larger figure title
    })
    
    if not schedule or all(len(ops) == 0 for ops in schedule.values()):
        print("No schedule to plot - schedule is empty")
        return

    colors = plt.cm.tab20.colors
    fig, ax = plt.subplots(figsize=(28, 16))  # Much larger figure for A0 poster
    fig.patch.set_facecolor('white')
    
    # Calculate max time for proper scaling
    max_time = 0
    for machine_ops in schedule.values():
        for op_data in machine_ops:
            if len(op_data) == 3:
                _, start, end = op_data
                max_time = max(max_time, end)
    
    # Add arrival times to max_time calculation
    for arrival in arrival_times.values():
        max_time = max(max_time, arrival)
    max_time = max_time * 1.1  # Add padding
    
    # Plot Gantt chart
    for idx, m in enumerate(machine_list):
        machine_ops = schedule.get(m, [])
        machine_ops.sort(key=lambda x: x[1])

        for op_data in machine_ops:
            if len(op_data) == 3:
                job_id_str, start, end = op_data
                try:
                    # Extract job number from "J0-O1"
                    j = int(job_id_str.split('-')[0][1:])
                except (ValueError, IndexError):
                    j = hash(job_id_str) % len(colors)
                
                ax.broken_barh(
                    [(start, end - start)],
                    (idx * 10, 8),
                    facecolors=colors[j % len(colors)],
                    edgecolor='black',
                    alpha=0.8,
                    linewidth=2  # Thicker lines for poster visibility
                )
                label = job_id_str
                ax.text(start + (end - start) / 2, idx * 10 + 4,
                       label, color='white', fontsize=24,  # Larger text in bars
                       ha='center', va='center', weight='bold')

    # Add job arrival indicators
    for job_id, arrival in arrival_times.items():
        if arrival > 0:
            ax.axvline(x=arrival, color='red', linestyle='--', linewidth=4, alpha=0.8)
            
            # Red arrow pointing down
            arrow_y = len(machine_list) * 10 + 5
            ax.annotate('', xy=(arrival, arrow_y - 3), xytext=(arrival, arrow_y + 2),
                       arrowprops=dict(arrowstyle='->', color='red', lw=3))
            
            # Job arrival label
            ax.text(arrival, arrow_y + 4, f'J{job_id}', ha='center', va='bottom',
                   color='red', fontweight='bold', fontsize=22,
                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='red', linewidth=2))

    ax.set_yticks([i * 10 + 4 for i in range(len(machine_list))])
    ax.set_yticklabels(machine_list)
    ax.set_xlabel("Time", fontsize=36, fontweight='bold')      # Increased label size
    ax.set_ylabel("Machines", fontsize=36, fontweight='bold')  # Increased label size
    ax.set_title(f"Dynamic RL Schedule - Makespan: {makespan:.2f}", fontsize=40, fontweight='bold')  # Increased title size
    ax.grid(True, alpha=0.3, linewidth=1.5)
    ax.set_xlim(0, max_time)
    
    # Create legend for jobs
    legend_elements = [
        plt.Rectangle((0, 0), 1, 1, facecolors=colors[i % len(colors)], 
                     edgecolor='black', label=f'Job {i}', linewidth=2) 
        for i in range(len(set(arrival_times.keys())))
    ]
    legend_elements.extend([
        plt.Line2D([0], [0], color='red', linestyle='--', linewidth=4, 
                  label='Job Arrival Time'),
        plt.Line2D([0], [0], marker='v', color='red', markersize=12, linestyle='None',
                  label='Arrival Indicator')
    ])
    
    ax.legend(handles=legend_elements, bbox_to_anchor=(1.02, 1), 
             loc='upper left', fontsize=26, frameon=True,   # Increased legend size
             fancybox=True, shadow=True)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"Dynamic RL Gantt chart saved to {save_path}")
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()

# --- 2. Dynamic RL Environment ---
def mask_fn(env: gym.Env) -> np.ndarray:
    return env.action_masks()

class GraphFeaturesExtractor(BaseFeaturesExtractor):
    """
    Enhanced Graph Neural Network feature extractor for GraphDFJSPEnv observations.
    """
    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 256):
        super().__init__(observation_space, features_dim)
        
        # Get dimensions from observation space
        node_features_shape = observation_space['node_features'].shape
        global_features_shape = observation_space['global_features'].shape
        
        self.num_nodes = node_features_shape[0]
        self.node_feature_dim = node_features_shape[1]
        self.global_feature_dim = global_features_shape[0]
        
        # Node embedding layers
        self.node_embedding = nn.Sequential(
            nn.Linear(self.node_feature_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 64)
        )
        
        # Graph Neural Network layers with attention
        self.gnn_layers = nn.ModuleList([
            nn.Linear(64, 128),
            nn.Linear(128, 128),
            nn.Linear(128, 64)
        ])
        
        # Global feature processing
        self.global_fc = nn.Sequential(
            nn.Linear(self.global_feature_dim, 32),
            nn.ReLU(),
            nn.Linear(32, 32)
        )
        
        # Attention mechanism for node aggregation
        self.attention = nn.Sequential(
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )
        
        # Final feature combination
        self.final_fc = nn.Sequential(
            nn.Linear(64 + 32, features_dim),
            nn.ReLU(),
            nn.Linear(features_dim, features_dim)
        )
        
    def forward(self, observations):
        node_features = observations['node_features']
        adjacency = observations['adjacency'] 
        global_features = observations['global_features']
        
        # Node embedding
        h = self.node_embedding(node_features)
        
        # Graph convolution layers
        for i, gnn_layer in enumerate(self.gnn_layers):
            # Message passing: aggregate neighbor features
            neighbor_features = torch.matmul(adjacency, h)
            
            # Combine self features with neighbor features
            combined = h + neighbor_features
            h = F.relu(gnn_layer(combined))
            
            # Apply dropout for regularization
            if self.training:
                h = F.dropout(h, p=0.1)
        
        # Attention-based graph pooling
        attention_weights = F.softmax(self.attention(h), dim=-2)
        graph_repr = torch.sum(attention_weights * h, dim=-2)
        
        # Process global features
        global_repr = self.global_fc(global_features)
        
        # Combine representations
        combined = torch.cat([graph_repr, global_repr], dim=-1)
        features = self.final_fc(combined)
        
        return features

class GraphMaskableActorCriticPolicy(MaskableActorCriticPolicy):
    """Custom policy using Graph Neural Network features extractor."""
    def __init__(self, *args, **kwargs):
        kwargs['features_extractor_class'] = GraphFeaturesExtractor
        kwargs['features_extractor_kwargs'] = {'features_dim': 256}
        super().__init__(*args, **kwargs)

class DynamicFJSPEnv(gym.Env):
    metadata = {"render.modes": ["human"]}

    def __init__(self, jobs_data, machine_list, job_arrival_times=None):
        super().__init__()
        self.jobs = jobs_data
        self.machines = machine_list
        self.job_ids = list(self.jobs.keys())
        self.num_jobs = len(self.job_ids)
        self.max_ops_per_job = max(len(ops) for ops in self.jobs.values()) if self.num_jobs > 0 else 1
        self.total_operations = sum(len(ops) for ops in self.jobs.values())
        
        if job_arrival_times is None:
            self.job_arrival_times = {job_id: 0 for job_id in self.job_ids}
        else:
            self.job_arrival_times = job_arrival_times

        self.action_space = spaces.Discrete(
            self.num_jobs * self.max_ops_per_job * len(self.machines)
        )
        
        obs_size = (
            len(self.machines) +  # Machine availability
            self.num_jobs * self.max_ops_per_job + # Operation completion
            self.num_jobs + # Job progress
            self.num_jobs + # Job arrival status
            1 # Current makespan
        )
        self.observation_space = spaces.Box(
            low=0.0, high=1.0, shape=(obs_size,), dtype=np.float32
        )
        self.reset()

    def reset(self, seed=None, options=None):
        if seed is not None:
            super().reset(seed=seed)
        
        self.machine_next_free = {m: 0.0 for m in self.machines}
        self.schedule = {m: [] for m in self.machines}
        self.completed_ops = {job_id: [False] * len(self.jobs[job_id]) for job_id in self.job_ids}
        self.operation_end_times = {job_id: [0.0] * len(self.jobs[job_id]) for job_id in self.job_ids}
        self.next_operation = {job_id: 0 for job_id in self.job_ids}
        
        self.current_makespan = 0.0
        self.operations_scheduled = 0
        
        # Handle job arrivals at time 0
        self.arrived_jobs = {
            job_id for job_id, arrival_time in self.job_arrival_times.items()
            if arrival_time <= 0
        }
        
        return self._get_observation(), {}

    def _decode_action(self, action):
        num_machines = len(self.machines)
        ops_per_job = self.max_ops_per_job
        
        job_idx = action // (ops_per_job * num_machines)
        op_idx = (action % (ops_per_job * num_machines)) // num_machines
        machine_idx = action % num_machines
        
        return job_idx, op_idx, machine_idx

    def _is_valid_action(self, job_idx, op_idx, machine_idx):
        # Check basic bounds
        if not (0 <= job_idx < self.num_jobs and 0 <= machine_idx < len(self.machines)):
            return False
        
        job_id = self.job_ids[job_idx]
        
        # Check if job has arrived
        if job_id not in self.arrived_jobs:
            return False
        
        # Check if operation index is valid for this specific job
        if not (0 <= op_idx < len(self.jobs[job_id])):
            return False
            
        # Check if this is the next operation to be scheduled for this job
        if op_idx != self.next_operation[job_id]:
            return False
            
        # Check if the machine can process this operation
        machine_name = self.machines[machine_idx]
        if machine_name not in self.jobs[job_id][op_idx]['proc_times']:
            return False
            
        return True

    def action_masks(self):
        mask = np.full(self.action_space.n, False, dtype=bool)
        
        if self.operations_scheduled >= self.total_operations:
            return mask

        for job_idx, job_id in enumerate(self.job_ids):
            if job_id not in self.arrived_jobs:
                continue

            op_idx = self.next_operation[job_id]
            
            # Only consider valid operation indices for this job
            if op_idx < len(self.jobs[job_id]):
                op_data = self.jobs[job_id][op_idx]
                
                for machine_idx, machine_name in enumerate(self.machines):
                    if machine_name in op_data['proc_times']:
                        action = job_idx * (self.max_ops_per_job * len(self.machines)) + \
                                 op_idx * len(self.machines) + machine_idx
                        
                        if action < self.action_space.n:
                            mask[action] = True
        
        # Debug: Print mask information
        valid_actions = np.sum(mask)
        if valid_actions == 0:
            print(f"WARNING: No valid actions available!")
            print(f"Operations scheduled: {self.operations_scheduled}/{self.total_operations}")
            print(f"Arrived jobs: {self.arrived_jobs}")
            print(f"Next operations: {self.next_operation}")
            for job_id in self.job_ids:
                if job_id in self.arrived_jobs:
                    next_op = self.next_operation[job_id]
                    if next_op < len(self.jobs[job_id]):
                        print(f"Job {job_id}, Op {next_op}: {self.jobs[job_id][next_op]['proc_times']}")
        
        return mask

    def step(self, action):
        job_idx, op_idx, machine_idx = self._decode_action(action)

        if not self._is_valid_action(job_idx, op_idx, machine_idx):
            print(f"Invalid action: job_idx={job_idx}, op_idx={op_idx}, machine_idx={machine_idx}")
            print(f"Available jobs: {list(self.arrived_jobs)}")
            print(f"Next operations: {self.next_operation}")
            return self._get_observation(), -100.0, True, False, {"error": "Invalid action taken"}

        job_id = self.job_ids[job_idx]
        machine = self.machines[machine_idx]
        
        machine_available_time = self.machine_next_free[machine]
        job_ready_time = self.operation_end_times[job_id][op_idx - 1] if op_idx > 0 else self.job_arrival_times[job_id]
        
        start_time = max(machine_available_time, job_ready_time)
        proc_time = self.jobs[job_id][op_idx]['proc_times'][machine]
        end_time = start_time + proc_time

        self.machine_next_free[machine] = end_time
        self.operation_end_times[job_id][op_idx] = end_time
        self.completed_ops[job_id][op_idx] = True
        self.next_operation[job_id] += 1
        self.operations_scheduled += 1
        
        # Update makespan and check for new arrivals
        previous_makespan = self.current_makespan
        self.current_makespan = max(self.current_makespan, end_time)
        
        newly_arrived = {
            j_id for j_id, arrival in self.job_arrival_times.items()
            if previous_makespan < arrival <= self.current_makespan
        }
        self.arrived_jobs.update(newly_arrived)

        self.schedule[machine].append((f"J{job_id}-O{op_idx+1}", start_time, end_time))

        terminated = self.operations_scheduled == self.total_operations
        
        # Enhanced reward calculation with action context
        reward = self._calculate_enhanced_reward(job_id, op_idx, machine, proc_time, 
                                               start_time - machine_available_time, terminated)
        
        info = {"makespan": self.current_makespan}
        return self._get_observation(), reward, terminated, False, info

    def _calculate_enhanced_reward(self, job_id, op_idx, machine, proc_time, idle_time, done):
        """Enhanced reward function with scheduling intelligence"""
        reward = 0.0
        
        # Base penalties
        reward -= proc_time * 0.1
        reward -= idle_time * 2.0
        
        # Progress reward
        reward += 1.0
        
        # Critical path awareness - prioritize jobs on potential critical path
        remaining_work = sum(
            min(op['proc_times'].values()) for op in self.jobs[job_id][op_idx+1:]
        ) if op_idx + 1 < len(self.jobs[job_id]) else 0
        
        # Jobs with more remaining work should be prioritized
        reward += remaining_work * 0.05
        
        # Machine utilization bonus - prefer machines that were idle
        if idle_time > 0:
            reward -= idle_time * 1.5  # Penalize, but less than before
        else:
            reward += 2.0  # Bonus for no idle time
        
        # Arrival time consideration - prioritize earlier arrivals
        arrival_bonus = max(0, 40 - self.job_arrival_times.get(job_id, 0)) * 0.1
        reward += arrival_bonus
        
        # Load balancing - slight bonus for using less utilized machines
        machine_utilization = self.machine_next_free[machine] / max(1, self.current_makespan)
        if machine_utilization < 0.8:  # If machine is relatively underutilized
            reward += 1.0
        
        if done:
            # Completion bonus with strong makespan penalty
            base_bonus = 200.0
            makespan_penalty = self.current_makespan * 1.5
            
            # Graduated bonuses for achieving specific targets
            if self.current_makespan <= 57.0:
                reward += base_bonus + 200.0  # Huge bonus for optimal
            elif self.current_makespan <= 57.5:
                reward += base_bonus + 150.0  # Large bonus for near-optimal
            elif self.current_makespan <= 58.0:
                reward += base_bonus + 100.0  # Good bonus
            elif self.current_makespan <= 58.5:
                reward += base_bonus + 50.0   # Moderate bonus
            
            reward -= makespan_penalty
        
        return reward

    def _get_observation(self):
        norm_factor = max(self.current_makespan, 100.0)
        
        obs = []
        
        # Machine availability (normalized)
        obs.extend([self.machine_next_free[m] / norm_factor for m in self.machines])
        
        # Operation completion status (padded to max_ops_per_job)
        for job_id in self.job_ids:
            for op_idx in range(self.max_ops_per_job):
                if op_idx < len(self.jobs[job_id]):
                    completed = 1.0 if self.completed_ops[job_id][op_idx] else 0.0
                else:
                    completed = 1.0  # Non-existent operations are considered "completed"
                obs.append(completed)
        
        # Job progress (proportion of operations completed)
        for job_id in self.job_ids:
            total_ops = len(self.jobs[job_id])
            progress = self.next_operation[job_id] / total_ops if total_ops > 0 else 1.0
            obs.append(progress)
            
        # Job arrival status
        for job_id in self.job_ids:
            obs.append(1.0 if job_id in self.arrived_jobs else 0.0)
            
        # Current makespan (normalized)
        obs.append(self.current_makespan / norm_factor)
        
        return np.array(obs, dtype=np.float32)

class GraphDFJSPEnv(gym.Env):
    """
    Graph-based DFJSP environment using node features and adjacency matrices.
    More scalable and expressive than fixed-size observation spaces.
    """
    metadata = {"render.modes": ["human"]}
    
    def __init__(self, jobs_data, machine_list, job_arrival_times=None):
        super().__init__()
        self.jobs = jobs_data
        self.machines = machine_list
        self.job_ids = list(self.jobs.keys())
        self.num_jobs = len(self.job_ids)
        self.num_machines = len(self.machines)
        
        # Create operation mapping
        self.operations = []
        self.job_to_ops = {}
        op_idx = 0
        for job_id in self.job_ids:
            self.job_to_ops[job_id] = []
            for op_pos in range(len(self.jobs[job_id])):
                self.operations.append((job_id, op_pos))
                self.job_to_ops[job_id].append(op_idx)
                op_idx += 1
        
        self.num_operations = len(self.operations)
        self.total_operations = self.num_operations
        
        if job_arrival_times is None:
            self.job_arrival_times = {job_id: 0 for job_id in self.job_ids}
        else:
            self.job_arrival_times = job_arrival_times
        
        # Create valid action pairs (operation_idx, machine)
        self.valid_action_pairs = []
        for op_idx, (job_id, op_pos) in enumerate(self.operations):
            for machine in self.jobs[job_id][op_pos]['proc_times']:
                self.valid_action_pairs.append((op_idx, machine))
        
        self.action_space = spaces.Discrete(len(self.valid_action_pairs))
        
        # Graph-based observation space
        self.observation_space = spaces.Dict({
            'node_features': spaces.Box(low=0, high=1, 
                                      shape=(self.num_operations + self.num_machines, 8), 
                                      dtype=np.float32),
            'adjacency': spaces.Box(low=0, high=1, 
                                  shape=(self.num_operations + self.num_machines, 
                                        self.num_operations + self.num_machines),
                                  dtype=np.float32),
            'global_features': spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)
        })
        
        self.reset()
    
    def reset(self, seed=None, options=None):
        if seed is not None:
            super().reset(seed=seed)
            
        # State tracking
        self.current_time = 0.0
        self.machine_available_time = {m: 0.0 for m in self.machines}
        self.operation_status = ['waiting'] * self.num_operations  # 'waiting', 'ready', 'running', 'done'
        self.operation_start_time = [None] * self.num_operations
        self.operation_end_time = [None] * self.num_operations
        self.job_next_op = {job_id: 0 for job_id in self.job_ids}
        self.schedule = {m: [] for m in self.machines}
        
        # Handle initial job arrivals (including time 0)
        self.arrived_jobs = {
            job_id for job_id, arrival_time in self.job_arrival_times.items()
            if arrival_time <= self.current_time
        }
        
        # Update initial ready operations
        self._update_ready_operations()
        
        return self._get_observation(), {}
    
    def _update_ready_operations(self):
        """Update which operations are ready to be scheduled"""
        for job_id in self.job_ids:
            # Check if job has arrived
            if self.job_arrival_times[job_id] <= self.current_time:
                next_op_pos = self.job_next_op[job_id]
                if next_op_pos < len(self.jobs[job_id]):
                    op_idx = self.job_to_ops[job_id][next_op_pos]
                    if self.operation_status[op_idx] == 'waiting':
                        # Check precedence constraints
                        if next_op_pos == 0 or self.operation_status[self.job_to_ops[job_id][next_op_pos - 1]] == 'done':
                            self.operation_status[op_idx] = 'ready'
    
    def _get_valid_actions(self):
        """Get mask of valid actions"""
        mask = np.zeros(self.action_space.n, dtype=bool)
        
        # If no operations are ready, we need to advance time
        if not any(self.operation_status[i] == 'ready' for i in range(self.num_operations)):
            # Find next job arrival or machine availability
            future_arrivals = [
                arrival for arrival in self.job_arrival_times.values() 
                if arrival > self.current_time
            ]
            
            if future_arrivals:
                next_time = min(future_arrivals)
                self.current_time = next_time
                
                # Update arrived jobs
                self.arrived_jobs.update({
                    job_id for job_id, arrival_time in self.job_arrival_times.items()
                    if arrival_time <= self.current_time
                })
                
                # Update ready operations
                self._update_ready_operations()
        
        # Mark valid actions
        for action_idx, (op_idx, machine) in enumerate(self.valid_action_pairs):
            if self.operation_status[op_idx] == 'ready':
                mask[action_idx] = True
                
        return mask
    
    def step(self, action):
        if not self._get_valid_actions()[action]:
            return self._get_observation(), -100.0, True, False, {"error": "Invalid action"}
        
        op_idx, machine = self.valid_action_pairs[action]
        job_id, op_pos = self.operations[op_idx]
        
        # Calculate start time properly
        proc_time = self.jobs[job_id][op_pos]['proc_times'][machine]
        machine_ready_time = self.machine_available_time[machine]
        
        # Job ready time (considering precedence)
        if op_pos > 0:
            prev_op_idx = self.job_to_ops[job_id][op_pos - 1]
            job_ready_time = self.operation_end_time[prev_op_idx] if self.operation_end_time[prev_op_idx] is not None else 0.0
        else:
            job_ready_time = self.job_arrival_times[job_id]
        
        start_time = max(self.current_time, machine_ready_time, job_ready_time)
        end_time = start_time + proc_time
        
        # Update state
        self.operation_status[op_idx] = 'done'
        self.operation_start_time[op_idx] = start_time
        self.operation_end_time[op_idx] = end_time
        self.machine_available_time[machine] = end_time
        self.current_time = max(self.current_time, end_time)
        self.job_next_op[job_id] += 1
        
        self.schedule[machine].append((f"J{job_id}-O{op_pos+1}", start_time, end_time))
        
        # Update arrived jobs based on current time
        self.arrived_jobs.update({
            job_id for job_id, arrival_time in self.job_arrival_times.items()
            if arrival_time <= self.current_time
        })
        
        # Update ready operations
        self._update_ready_operations()
        
        # Check if done
        done = all(status == 'done' for status in self.operation_status)
        
        # Calculate reward (fixed idle time calculation)
        idle_time = start_time - machine_ready_time
        reward = self._calculate_reward(proc_time, idle_time, done)
        
        info = {"makespan": self.current_time}
        return self._get_observation(), reward, done, False, info
    
    def _get_observation(self):
        """Create improved graph-based observation"""
        num_nodes = self.num_operations + self.num_machines
        node_features = np.zeros((num_nodes, 8), dtype=np.float32)
        adjacency = np.zeros((num_nodes, num_nodes), dtype=np.float32)
        
        # Operation node features
        for op_idx, (job_id, op_pos) in enumerate(self.operations):
            # Feature 0: Operation is ready to schedule
            node_features[op_idx, 0] = 1.0 if self.operation_status[op_idx] == 'ready' else 0.0
            
            # Feature 1: Operation is completed
            node_features[op_idx, 1] = 1.0 if self.operation_status[op_idx] == 'done' else 0.0
            
            # Feature 2: Minimum processing time (normalized)
            proc_times = list(self.jobs[job_id][op_pos]['proc_times'].values())
            min_proc_time = min(proc_times)
            node_features[op_idx, 2] = min_proc_time / 20.0  # Normalize by estimated max
            
            # Feature 3: Number of machine options (flexibility)
            node_features[op_idx, 3] = len(proc_times) / self.num_machines
            
            # Feature 4: Job progress ratio
            job_ops = len(self.jobs[job_id])
            node_features[op_idx, 4] = op_pos / max(1, job_ops - 1) if job_ops > 1 else 1.0
            
            # Feature 5: Job has arrived
            node_features[op_idx, 5] = 1.0 if job_id in self.arrived_jobs else 0.0
            
            # Feature 6: Operation position in job
            node_features[op_idx, 6] = op_pos / max(1, job_ops - 1) if job_ops > 1 else 0.0
            
            # Feature 7: Time since job arrival (normalized)
            if job_id in self.arrived_jobs:
                time_since_arrival = max(0, self.current_time - self.job_arrival_times[job_id])
                node_features[op_idx, 7] = min(1.0, time_since_arrival / 50.0)
            
        # Machine node features
        for m_idx, machine in enumerate(self.machines):
            machine_node_idx = self.num_operations + m_idx
            
            # Feature 0: Machine is available now
            node_features[machine_node_idx, 0] = 1.0 if self.machine_available_time[machine] <= self.current_time else 0.0
            
            # Feature 1: Machine availability time (normalized)
            node_features[machine_node_idx, 1] = min(1.0, self.machine_available_time[machine] / max(1.0, self.current_time + 20))
            
            # Feature 2: Machine utilization
            if self.current_time > 0:
                node_features[machine_node_idx, 2] = min(1.0, self.machine_available_time[machine] / self.current_time)
            
            # Feature 3-7: Reserved for machine-specific features
            
        # Build adjacency matrix
        # 1. Precedence edges (operation to next operation in same job)
        for job_id in self.job_ids:
            job_ops = self.job_to_ops[job_id]
            for i in range(len(job_ops) - 1):
                adjacency[job_ops[i], job_ops[i + 1]] = 1.0
        
        # 2. Machine compatibility edges (operation to compatible machines)
        for op_idx, (job_id, op_pos) in enumerate(self.operations):
            for machine in self.jobs[job_id][op_pos]['proc_times']:
                machine_idx = self.machines.index(machine)
                machine_node_idx = self.num_operations + machine_idx
                adjacency[op_idx, machine_node_idx] = 1.0
                # Bidirectional edge
                adjacency[machine_node_idx, op_idx] = 1.0
        
        # Global features: [time_progress, completion_rate, machine_util, job_arrival_rate]
        total_proc_time_estimate = sum(
            min(op['proc_times'].values()) 
            for job_ops in self.jobs.values() 
            for op in job_ops
        )
        
        global_features = np.array([
            min(1.0, self.current_time / max(1.0, total_proc_time_estimate)),  # Time progress
            sum(1 for s in self.operation_status if s == 'done') / len(self.operation_status),  # Completion rate
            np.mean([min(1.0, self.machine_available_time[m] / max(1.0, self.current_time)) for m in self.machines]),  # Avg machine util
            len(self.arrived_jobs) / len(self.job_ids)  # Job arrival rate
        ], dtype=np.float32)
        
        return {
            'node_features': node_features,
            'adjacency': adjacency,
            'global_features': global_features
        }
    
    def _calculate_reward(self, proc_time, idle_time, done):
        # More balanced reward function
        reward = 0.0
        
        # Penalize processing time (encourage shorter operations)
        reward -= proc_time * 0.1
        
        # Penalize machine idle time more heavily
        reward -= idle_time * 0.5
        
        # Encourage finishing operations quickly
        reward += 10.0  # Base reward for completing an operation
        
        if done:
            # Large completion bonus, but penalize final makespan
            reward += 100.0 - self.current_time * 0.5
        
        return reward

    def get_action_mask(self):
        """For compatibility with MaskablePPO"""
        return self._get_valid_actions()
    
    def action_masks(self):
        """For compatibility with ActionMasker"""
        return self._get_valid_actions()

# --- 3. Training and Evaluation ---
def train_agent(jobs_data, machine_list, train_arrivals, log_name, total_timesteps=150000):
    print(f"\n--- Training Agent: {log_name} ---")
    
    def make_train_env():
        env = DynamicFJSPEnv(jobs_data, machine_list, train_arrivals)
        env = ActionMasker(env, mask_fn)
        return Monitor(env)

    vec_env = DummyVecEnv([make_train_env])
    
    # Enhanced hyperparameters for better optimization
    model = MaskablePPO(
        MaskableActorCriticPolicy, 
        vec_env, 
        verbose=1,
        n_steps=4096,          # Increased for more experience per update
        batch_size=128,        # Larger batch for more stable gradients
        n_epochs=20,           # More epochs for better policy refinement
        gamma=0.995,           # Higher discount for long-term optimization
        ent_coef=0.005,        # Lower entropy for more exploitation
        learning_rate=1e-4,    # Lower learning rate for fine-tuning
        clip_range=0.1,        # Tighter clipping for stability
        vf_coef=0.8,           # Higher value function coefficient
        max_grad_norm=0.3,     # Stricter gradient clipping
        target_kl=0.01         # Tight KL divergence for stable updates
    )
    
    print(f"Training for {total_timesteps} timesteps...")
    model.learn(total_timesteps=total_timesteps, progress_bar=True)
    
    return model

def train_enhanced_agent(jobs_data, machine_list, train_arrivals, log_name, total_timesteps=200000):
    """Enhanced training with better hyperparameters for optimal performance"""
    print(f"\n--- Enhanced Training Agent: {log_name} ---")
    
    def make_train_env():
        env = DynamicFJSPEnv(jobs_data, machine_list, train_arrivals)
        env = ActionMasker(env, mask_fn)
        return Monitor(env)

    vec_env = DummyVecEnv([make_train_env])
    
    # Single phase training with optimized hyperparameters for precision
    print("Enhanced training with precision-focused hyperparameters...")
    model = MaskablePPO(
        MaskableActorCriticPolicy, 
        vec_env, 
        verbose=1,
        n_steps=4096,           # More experience per update
        batch_size=128,         # Larger batch for stability
        n_epochs=20,            # More epochs for better convergence
        gamma=0.995,            # Higher discount for long-term rewards
        ent_coef=0.003,         # Low entropy for exploitation
        learning_rate=8e-5,     # Lower learning rate for precision
        clip_range=0.15,        # Moderate clipping
        vf_coef=0.8,            # High value function importance
        max_grad_norm=0.3       # Strict gradient clipping
    )
    
    model.learn(total_timesteps=total_timesteps, progress_bar=True)
    
    return model

def evaluate_agent(model, jobs_data, machine_list, eval_arrivals, scenario_name):
    """Standard single evaluation for compatibility"""
    print(f"\n--- Evaluating Agent on Scenario: {scenario_name} ---")
    
    def make_eval_env():
        return DynamicFJSPEnv(jobs_data, machine_list, eval_arrivals)

    eval_env = make_eval_env()
    obs, _ = eval_env.reset()
    done = False
    
    while not done:
        action_masks = get_action_masks(eval_env)
        action, _ = model.predict(obs, action_masks=action_masks, deterministic=True)
        obs, _, done, _, info = eval_env.step(action)

    final_makespan = info.get("makespan", float('inf'))
    print(f"Evaluation complete. Final Makespan: {final_makespan:.2f}")
    
    return final_makespan, eval_env.schedule

def evaluate_agent_multiple_runs(model, jobs_data, machine_list, eval_arrivals, scenario_name, num_runs=10):
    """Evaluate agent multiple times and return the best result"""
    print(f"\n--- Multiple Evaluation of Agent: {scenario_name} ({num_runs} runs) ---")
    
    best_makespan = float('inf')
    best_schedule = None
    makespans = []
    
    for run in range(num_runs):
        def make_eval_env():
            env = DynamicFJSPEnv(jobs_data, machine_list, eval_arrivals)
            # Add slight randomization to break ties differently
            np.random.seed(42 + run)
            return env

        eval_env = make_eval_env()
        obs, _ = eval_env.reset()
        done = False
        
        while not done:
            action_masks = get_action_masks(eval_env)
            action, _ = model.predict(obs, action_masks=action_masks, deterministic=True)
            obs, _, done, _, info = eval_env.step(action)

        final_makespan = info.get("makespan", float('inf'))
        makespans.append(final_makespan)
        
        if final_makespan < best_makespan:
            best_makespan = final_makespan
            best_schedule = eval_env.schedule.copy()
        
        print(f"  Run {run+1}: Makespan = {final_makespan:.2f}")
    
    avg_makespan = np.mean(makespans)
    std_makespan = np.std(makespans)
    
    print(f"Best Makespan: {best_makespan:.2f}")
    print(f"Average Makespan: {avg_makespan:.2f} ± {std_makespan:.2f}")
    print(f"Gap from optimal (57): {((best_makespan - 57) / 57 * 100):.2f}%")
    
    return best_makespan, best_schedule

# --- 4. Heuristic Scheduler ---
def heuristic_spt_scheduler(jobs_data, machine_list, job_arrival_times):
    """
    Schedules jobs based on the Shortest Processing Time (SPT) heuristic,
    considering dynamic job arrivals.
    """
    print("\n--- Running SPT Heuristic Scheduler ---")
    
    machine_next_free = {m: 0.0 for m in machine_list}
    operation_end_times = {job_id: [0.0] * len(jobs_data[job_id]) for job_id in jobs_data}
    next_operation_for_job = {job_id: 0 for job_id in jobs_data}
    
    schedule = {m: [] for m in machine_list}
    operations_scheduled_count = 0
    total_operations = sum(len(ops) for ops in jobs_data.values())
    
    arrived_jobs = {job_id for job_id, arrival in job_arrival_times.items() if arrival <= 0}
    
    while operations_scheduled_count < total_operations:
        candidate_operations = []
        
        # Find the earliest time a machine becomes free to advance time
        if not any(next_operation_for_job[job_id] < len(jobs_data[job_id]) for job_id in arrived_jobs):
             # If no available jobs have pending operations, advance time to next arrival
            upcoming_arrivals = [arr for arr in job_arrival_times.values() if arr > min(machine_next_free.values())]
            if not upcoming_arrivals: break # No more jobs will arrive
            
            next_arrival_time = min(upcoming_arrivals)
            for m in machine_list:
                if machine_next_free[m] < next_arrival_time:
                    machine_next_free[m] = next_arrival_time
            
            arrived_jobs.update({job_id for job_id, arrival in job_arrival_times.items() if arrival <= next_arrival_time})

        for job_id in arrived_jobs:
            op_idx = next_operation_for_job[job_id]
            if op_idx < len(jobs_data[job_id]):
                op_data = jobs_data[job_id][op_idx]
                job_ready_time = operation_end_times[job_id][op_idx - 1] if op_idx > 0 else job_arrival_times[job_id]
                
                for machine_name, proc_time in op_data['proc_times'].items():
                    earliest_start_time = max(machine_next_free[machine_name], job_ready_time)
                    candidate_operations.append((
                        proc_time,
                        earliest_start_time,
                        job_id, 
                        op_idx, 
                        machine_name
                    ))
        
        if not candidate_operations:
            break

        # Select the operation with the shortest processing time
        selected_op = min(candidate_operations, key=lambda x: x[0])
        proc_time, start_time, job_id, op_idx, machine_name = selected_op
        
        end_time = start_time + proc_time

        machine_next_free[machine_name] = end_time
        operation_end_times[job_id][op_idx] = end_time
        next_operation_for_job[job_id] += 1
        operations_scheduled_count += 1
        
        schedule[machine_name].append((f"J{job_id}-O{op_idx+1}", start_time, end_time))
        
        # Update arrived jobs based on new machine free times
        current_time = min(t for t in machine_next_free.values() if t > 0)
        arrived_jobs.update({j_id for j_id, arrival in job_arrival_times.items() if arrival <= current_time})

    makespan = max(machine_next_free.values()) if machine_next_free else 0
    print(f"SPT Heuristic Makespan: {makespan:.2f}")
    return makespan, schedule

# --- 5. MILP Optimal Scheduler ---
def milp_scheduler(jobs, machines, arrival_times):
    """MILP approach for optimal dynamic scheduling."""
    print("\n--- Running MILP Optimal Scheduler ---")
    prob = LpProblem("DynamicFJSP_Optimal", LpMinimize)
    
    ops = [(j, oi) for j in jobs for oi in range(len(jobs[j]))]
    BIG_M = 1000 

    x = LpVariable.dicts("x", (ops, machines), cat="Binary")
    s = LpVariable.dicts("s", ops, lowBound=0)
    c = LpVariable.dicts("c", ops, lowBound=0)
    y = LpVariable.dicts("y", (ops, ops, machines), cat="Binary")
    Cmax = LpVariable("Cmax", lowBound=0)

    prob += Cmax

    for j, oi in ops:
        # Assignment constraint
        prob += lpSum(x[j, oi][m] for m in jobs[j][oi]['proc_times']) == 1
        # Completion time
        prob += c[j, oi] == s[j, oi] + lpSum(x[j, oi][m] * jobs[j][oi]['proc_times'][m] for m in jobs[j][oi]['proc_times'])
        # Precedence within a job
        if oi > 0:
            prob += s[j, oi] >= c[j, oi - 1]
        # Arrival time constraint
        else:
            prob += s[j, oi] >= arrival_times[j]
        # Makespan definition
        prob += Cmax >= c[j, oi]

    for m in machines:
        ops_on_m = [op for op in ops if m in jobs[op[0]][op[1]]['proc_times']]
        for i in range(len(ops_on_m)):
            for k in range(i + 1, len(ops_on_m)):
                op1, op2 = ops_on_m[i], ops_on_m[k]
                # Disjunctive constraints
                prob += s[op1] >= c[op2] - BIG_M * (1 - y[op1][op2][m]) - BIG_M * (2 - x[op1][m] - x[op2][m])
                prob += s[op2] >= c[op1] - BIG_M * y[op1][op2][m] - BIG_M * (2 - x[op1][m] - x[op2][m])

    prob.solve(PULP_CBC_CMD(msg=False, timeLimit=120)) # 2-minute time limit

    schedule = {m: [] for m in machines}
    if Cmax.varValue is not None:
        for (j, oi), m in ((op, m) for op in ops for m in jobs[op[0]][op[1]]['proc_times']):
            if x[j, oi][m].varValue > 0.5:
                schedule[m].append((f"J{j}-O{oi+1}", s[j, oi].varValue, c[j, oi].varValue))
        print(f"MILP (optimal) Makespan: {Cmax.varValue:.2f}")
        return Cmax.varValue, schedule
    # return float('inf'), schedule

# --- 6. Main Execution Block ---
def plot_gantt_charts(figure_num, schedules, makespans, titles, machine_list, arrival_times, save_path=None):
    """Plot multiple Gantt charts with arrival indicators and A0 poster formatting."""
    # Set font configuration for A0 poster visibility
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 26,           # Increased base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility
        'axes.titlesize': 36,      # Much larger title
        'axes.labelsize': 32,      # Much larger axis labels
        'xtick.labelsize': 28,     # Much larger tick labels
        'ytick.labelsize': 28,     # Much larger tick labels
        'legend.fontsize': 24,     # Much larger legend
        'figure.titlesize': 40     # Much larger figure title
    })
    
    num_charts = len(schedules)
    fig = plt.figure(figure_num, figsize=(32, num_charts * 10))  # Much larger for A0 poster to prevent overlap
    fig.patch.set_facecolor('white')
    
    colors = plt.cm.tab20.colors
    
    # Calculate the maximum time across all schedules to ensure consistent x-axis scale
    max_time = 0
    for schedule in schedules:
        if schedule:  # Check if schedule is not empty
            for machine_ops in schedule.values():
                for op_data in machine_ops:
                    if len(op_data) == 3:
                        _, start, end = op_data
                        max_time = max(max_time, end)
    
    # Also consider arrival times for x-axis scaling
    if isinstance(arrival_times, list):
        for arrival_dict in arrival_times:
            for arrival in arrival_dict.values():
                max_time = max(max_time, arrival)
    else:
        for arrival in arrival_times.values():
            max_time = max(max_time, arrival)
    
    # Add some padding to the max time for better visualization
    max_time = max_time * 1.05

    for i, (schedule, makespan, title) in enumerate(zip(schedules, makespans, titles)):
        ax = fig.add_subplot(num_charts, 1, i + 1)
        for idx, m in enumerate(machine_list):
            for op_data in schedule.get(m, []):
                job_id_str, start, end = op_data
                j = int(job_id_str.split('-')[0][1:])
                ax.broken_barh([(start, end - start)], (idx * 10, 8),
                               facecolors=colors[j % len(colors)], 
                               edgecolor='black', alpha=0.8, linewidth=2)
                ax.text(start + (end - start) / 2, idx * 10 + 4, job_id_str,
                        color='white', ha='center', va='center', 
                        weight='bold', fontsize=22)  # Increased text size in bars
        
        # Use the correct arrival times for the specific scenario being plotted
        current_arrival_times = arrival_times[i] if isinstance(arrival_times, list) else arrival_times
        for job_id, arrival in current_arrival_times.items():
            if arrival > 0:
                ax.axvline(x=arrival, color='r', linestyle='--', linewidth=3, alpha=0.8)
                ax.annotate(f'J{job_id} Arrives', xy=(arrival, len(machine_list) * 10),
                            xytext=(arrival + 1, len(machine_list) * 10 + 4),
                            arrowprops=dict(facecolor='red', shrink=0.05, width=3),
                            color='red', ha='left', fontsize=22, fontweight='bold')  # Increased arrival annotation size

        ax.set_yticks([k * 10 + 4 for k in range(len(machine_list))])
        ax.set_yticklabels(machine_list)
        ax.set_ylabel("Machines", fontsize=32, fontweight='bold')  # Increased label size
        ax.set_title(f"{title} - Makespan: {makespan:.2f}", fontsize=36, fontweight='bold')  # Increased title size
        ax.grid(True, alpha=0.4, linewidth=1.5)
        
        # Set consistent x-axis limits for all subplots
        ax.set_xlim(0, max_time)
        
        if i < num_charts - 1:
            ax.tick_params(labelbottom=False)
    
    plt.xlabel("Time", fontsize=32, fontweight='bold')  # Increased xlabel size
    plt.tight_layout(rect=[0, 0, 1, 0.98])
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"Figure saved to {save_path}")
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()

def plot_rl_comparison_with_poisson(static_schedule, dynamic_schedule, static_makespan, dynamic_makespan, 
                                    machine_list, arrival_times, save_path=None):
    """
    Create Figure 2: Comparison of Static RL vs Dynamic RL on dynamic job arrivals
    with Poisson distribution visualization and enhanced job arrival indicators.
    Optimized for A0 poster with Segoe UI font.
    """
    # Set font configuration for A0 poster visibility
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 22,           # Large base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility
        'axes.titlesize': 28,      # Large title
        'axes.labelsize': 26,      # Large axis labels
        'xtick.labelsize': 22,     # Large tick labels
        'ytick.labelsize': 22,     # Large tick labels
        'legend.fontsize': 20,     # Large legend
        'figure.titlesize': 32     # Large figure title
    })
    
    # Set up the figure with 3 subplots: Poisson distribution, Static RL, Dynamic RL
    fig = plt.figure(figsize=(28, 18))  # Much larger for A0 poster
    gs = fig.add_gridspec(3, 1, height_ratios=[1, 1.5, 1.5], hspace=0.35)
    fig.patch.set_facecolor('white')
    
    colors = plt.cm.tab20.colors
    
    # Calculate max time for consistent scaling
    max_time = 0
    for schedule in [static_schedule, dynamic_schedule]:
        if schedule:
            for machine_ops in schedule.values():
                for op_data in machine_ops:
                    if len(op_data) == 3:
                        _, start, end = op_data
                        max_time = max(max_time, end)
    
    # Add arrival times to max_time calculation
    for arrival in arrival_times.values():
        max_time = max(max_time, arrival)
    max_time = max_time * 1.1  # Add padding
    
    # Subplot 1: Poisson Distribution Visualization
    ax_poisson = fig.add_subplot(gs[0])
    
    # Generate Poisson distribution with lambda = 5 (average interval of 5 units)
    lambda_param = 10
    x_poisson = np.arange(0, 15)
    poisson_prob = np.exp(-lambda_param) * (lambda_param ** x_poisson) / np.array([math.factorial(x) for x in x_poisson])
    
    # Plot Poisson distribution
    bars = ax_poisson.bar(x_poisson, poisson_prob, alpha=0.7, color='skyblue', edgecolor='navy', linewidth=2)
    ax_poisson.set_xlabel('Inter-arrival Time (units)', fontsize=26, fontweight='bold')
    ax_poisson.set_ylabel('Probability', fontsize=26, fontweight='bold')
    ax_poisson.set_title(f'Job Arrival Pattern - Poisson Distribution (λ={lambda_param})', fontsize=28, fontweight='bold')
    ax_poisson.grid(True, alpha=0.3, linewidth=1.5)
    
    # Highlight the actual arrival intervals used in the problem
    actual_intervals = []
    arrival_list = sorted(arrival_times.items(), key=lambda x: x[1])
    for i in range(1, len(arrival_list)):
        interval = arrival_list[i][1] - arrival_list[i-1][1]
        if interval > 0:  # Only count positive intervals
            actual_intervals.append(interval)
    
    # Mark actual intervals on the Poisson plot
    for interval in actual_intervals:
        if interval < len(x_poisson):
            bars[interval].set_color('red')
            bars[interval].set_alpha(0.9)
    
    # Add text annotation for actual intervals
    ax_poisson.text(0.98, 0.95, f'Actual intervals: {actual_intervals}\nAverage: {np.mean(actual_intervals):.1f}', 
                   transform=ax_poisson.transAxes, ha='right', va='top', fontsize=20,
                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='black', linewidth=2))
    
    # Subplot 2: Static RL Performance on Dynamic Case
    ax_static = fig.add_subplot(gs[1])
    
    for idx, m in enumerate(machine_list):
        for op_data in static_schedule.get(m, []):
            job_id_str, start, end = op_data
            j = int(job_id_str.split('-')[0][1:])
            ax_static.broken_barh([(start, end - start)], (idx * 10, 8),
                                facecolors=colors[j % len(colors)], edgecolor='black', 
                                alpha=0.8, linewidth=2)
            ax_static.text(start + (end - start) / 2, idx * 10 + 4, job_id_str,
                          color='white', ha='center', va='center', weight='bold', fontsize=18)
    
    # Enhanced job arrival indicators for static RL
    arrival_heights = []
    for job_id, arrival in arrival_times.items():
        if arrival > 0:
            # Red dashed line for arrival
            ax_static.axvline(x=arrival, color='red', linestyle='--', linewidth=4, alpha=0.8)
            
            # Red arrow pointing down
            arrow_y = len(machine_list) * 10 + 5
            ax_static.annotate('', xy=(arrival, arrow_y - 3), xytext=(arrival, arrow_y + 2),
                             arrowprops=dict(arrowstyle='->', color='red', lw=3))
            
            # Job arrival label
            ax_static.text(arrival, arrow_y + 4, f'J{job_id}', ha='center', va='bottom',
                          color='red', fontweight='bold', fontsize=20,
                          bbox=dict(boxstyle='round,pad=0.3', facecolor='white', 
                                  edgecolor='red', linewidth=2))
            
            arrival_heights.append(arrow_y + 6)
    
    ax_static.set_yticks([k * 10 + 4 for k in range(len(machine_list))])
    ax_static.set_yticklabels(machine_list)
    ax_static.set_ylabel("Machines", fontsize=26, fontweight='bold')
    ax_static.set_title(f"Static RL on Dynamic Arrivals - Makespan: {static_makespan:.2f}", 
                       fontsize=28, fontweight='bold')
    ax_static.grid(True, alpha=0.4, linewidth=1.5)
    ax_static.set_xlim(0, max_time)
    ax_static.tick_params(labelbottom=False)
    
    # Subplot 3: Dynamic RL Performance on Dynamic Case
    ax_dynamic = fig.add_subplot(gs[2])
    
    for idx, m in enumerate(machine_list):
        for op_data in dynamic_schedule.get(m, []):
            job_id_str, start, end = op_data
            j = int(job_id_str.split('-')[0][1:])
            ax_dynamic.broken_barh([(start, end - start)], (idx * 10, 8),
                                 facecolors=colors[j % len(colors)], edgecolor='black', 
                                 alpha=0.8, linewidth=2)
            ax_dynamic.text(start + (end - start) / 2, idx * 10 + 4, job_id_str,
                           color='white', ha='center', va='center', weight='bold', fontsize=18)
    
    # Enhanced job arrival indicators for dynamic RL
    for job_id, arrival in arrival_times.items():
        if arrival > 0:
            # Red dashed line for arrival
            ax_dynamic.axvline(x=arrival, color='red', linestyle='--', linewidth=4, alpha=0.8)
            
            # Red arrow pointing down
            arrow_y = len(machine_list) * 10 + 5
            ax_dynamic.annotate('', xy=(arrival, arrow_y - 3), xytext=(arrival, arrow_y + 2),
                               arrowprops=dict(arrowstyle='->', color='red', lw=3))
            
            # Job arrival label
            ax_dynamic.text(arrival, arrow_y + 4, f'J{job_id}', ha='center', va='bottom',
                           color='red', fontweight='bold', fontsize=20,
                           bbox=dict(boxstyle='round,pad=0.3', facecolor='white', 
                                   edgecolor='red', linewidth=2))
    
    ax_dynamic.set_yticks([k * 10 + 4 for k in range(len(machine_list))])
    ax_dynamic.set_yticklabels(machine_list)
    ax_dynamic.set_ylabel("Machines", fontsize=26, fontweight='bold')
    ax_dynamic.set_xlabel("Time", fontsize=26, fontweight='bold')
    ax_dynamic.set_title(f"Dynamic RL on Dynamic Arrivals - Makespan: {dynamic_makespan:.2f}", 
                        fontsize=28, fontweight='bold')
    ax_dynamic.grid(True, alpha=0.4, linewidth=1.5)
    ax_dynamic.set_xlim(0, max_time)
    
    # Add comprehensive legend
    legend_elements = [
        plt.Rectangle((0, 0), 1, 1, facecolor=colors[i % len(colors)], 
                     edgecolor='black', label=f'Job {i}', linewidth=2) 
        for i in range(len(set(arrival_times.keys())))
    ]
    legend_elements.extend([
        plt.Line2D([0], [0], color='red', linestyle='--', linewidth=4, 
                  label='Job Arrival Time'),
        plt.Line2D([0], [0], marker='v', color='red', markersize=12, linestyle='None',
                  label='Arrival Indicator')
    ])
    
    # Position legend outside the plot
    ax_dynamic.legend(handles=legend_elements, bbox_to_anchor=(1.02, 1), 
                     loc='upper left', fontsize=20, frameon=True, 
                     fancybox=True, shadow=True)
    
    # Add performance comparison text box
    improvement = ((static_makespan - dynamic_makespan) / static_makespan) * 100
    comparison_text = f"""
Performance Comparison:
Static RL Makespan: {static_makespan:.2f}
Dynamic RL Makespan: {dynamic_makespan:.2f}
Improvement: {improvement:.1f}%
    """
    
    fig.text(0.02, 0.02, comparison_text.strip(), fontsize=22, fontweight='bold',
            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8, 
                     edgecolor='darkblue', linewidth=2),
            verticalalignment='bottom')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"Enhanced Figure 2 saved to {save_path}")
    
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()

def plot_job_structure_table(jobs_data, machine_list, arrival_times, save_path=None):
    """Create a table figure showing the job data structure with no title and A0 poster formatting."""
    # Set font for A0 poster presentation - Segoe UI for better readability
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 16,           # Larger base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility when scaled
        'axes.titlesize': 24,      # Large title size
        'figure.titlesize': 28     # Large figure title
    })
    
    # Create figure with dimensions optimized for A0 poster
    fig, ax = plt.subplots(figsize=(16, 12))  # Larger dimensions for poster
    fig.patch.set_facecolor('white')  # White background for contrast against dark blue poster
    ax.axis('tight')
    ax.axis('off')
    
    # Prepare table data with compact headers
    table_data = []
    headers = ['Job', 'Arrive', 'Op', 'Machines', 'Times']  # Shortened headers for compactness
    
    # High contrast color scheme for poster readability
    job_colors = [
        '#FFFFFF',  # Pure white for maximum contrast
        '#F0F0F0',  # Light gray
        '#E0E0E0',  # Medium light gray
        '#D8D8D8',  # Medium gray
        '#D0D0D0',  # Darker gray
        '#C8C8C8',  # Darkest gray
        '#F8F8F8'   # Extra light if needed
    ]
    
    for job_id, operations in jobs_data.items():
        arrival_time = arrival_times.get(job_id, 'N/A')
        
        for op_idx, operation in enumerate(operations):
            machines = list(operation['proc_times'].keys())
            # Clean processing times format
            proc_times = [f"{m}: {operation['proc_times'][m]}" for m in machines]
            
            row = [
                f'Job {job_id}' if op_idx == 0 else '',
                str(arrival_time) if op_idx == 0 else '',
                f'{op_idx + 1}',
                ', '.join(machines),
                ', '.join(proc_times)
            ]
            table_data.append(row)
    
    # Create table optimized for A0 poster layout
    table = ax.table(cellText=table_data, colLabels=headers, loc='center', cellLoc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(14)   # Larger font for A0 poster readability
    table.scale(1.2, 1.0)    # Wider table for better visibility on poster
    
    # Enhanced header styling with Segoe UI for poster readability
    header_color = '#2E4A62'  # Dark blue header for strong contrast
    for i in range(len(headers)):
        cell = table[(0, i)]
        cell.set_facecolor(header_color)
        cell.set_text_props(color='white', fontsize=16, fontweight='bold', fontfamily='Segoe UI')
        cell.set_height(0.06)  # Larger header height for poster
        cell.set_edgecolor('#000000')
        cell.set_linewidth(2.0)  # Thicker borders for poster visibility
        
        # Optimized column widths for poster format readability
        if i == 0:      # Job
            cell.set_width(0.12)
        elif i == 1:    # Arrive  
            cell.set_width(0.15)
        elif i == 2:    # Op
            cell.set_width(0.12)
        elif i == 3:    # Machines
            cell.set_width(0.30)
        elif i == 4:    # Times
            cell.set_width(0.31)
    
    # Enhanced row styling with maximum readability for A0 poster
    current_job = None
    color_idx = 0
    for i, row in enumerate(table_data):
        job_str = row[0]
        if job_str:  # New job detected
            current_job = int(job_str.split()[1])
            color_idx = current_job % len(job_colors)
        
        # Apply high contrast colors optimized for poster scaling
        bg_color = job_colors[color_idx]
        for j in range(len(headers)):
            cell = table[(i + 1, j)]
            cell.set_facecolor(bg_color)
            cell.set_text_props(fontfamily='Segoe UI', fontsize=12, fontweight='bold', color='#000000')
            cell.set_height(0.05)  # Larger row height for poster visibility
            cell.set_edgecolor('#333333')
            cell.set_linewidth(1.5)  # Thicker borders for poster
            
            # Match column widths to headers for consistency
            if j == 0:      # Job
                cell.set_width(0.12)
            elif j == 1:    # Arrive
                cell.set_width(0.15)
            elif j == 2:    # Op
                cell.set_width(0.12)
            elif j == 3:    # Machines
                cell.set_width(0.30)
            elif j == 4:    # Times
                cell.set_width(0.31)
            
            # Make job names and arrival times stand out with bold and color
            if j == 0 and row[j]:  # Job column
                cell.set_text_props(fontweight='bold', fontsize=14, color='#1A237E', fontfamily='Segoe UI')
            elif j == 1 and row[j]:  # Arrival column
                cell.set_text_props(fontweight='bold', fontsize=13, color='#3F51B5', fontfamily='Segoe UI')
    
    # Add strong borders to all cells for definition on poster
    for key, cell in table.get_celld().items():
        cell.set_edgecolor('#333333')
        cell.set_linewidth(1.5)  # Thicker borders for poster visibility
    
    # Remove title as requested
    
    # Optimize layout for A0 poster format
    plt.tight_layout(rect=[0.02, 0.02, 0.98, 0.98])  # Maximum space utilization
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"Job structure table saved to {save_path}")
    
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()

def visualize_action_mask(env, mask, jobs_data, machine_list, save_path=None):
    """
    Create a visualization of the action mask showing valid operations by machine with legend indicators.
    """
    # Set font configuration for A0 poster visibility
    plt.rcParams.update({
        'font.family': 'sans-serif',
        'font.sans-serif': ['Segoe UI', 'Arial', 'DejaVu Sans', 'Liberation Sans'],
        'font.size': 18,           # Large base font for A0 poster
        'font.weight': 'bold',     # Bold for better visibility
        'axes.titlesize': 24,      # Large title
        'axes.labelsize': 20,      # Large axis labels
        'xtick.labelsize': 16,     # Large tick labels
        'ytick.labelsize': 16,     # Large tick labels
        'legend.fontsize': 18,     # Large legend
    })
    
    fig, ax = plt.subplots(1, 1, figsize=(14, 10))  # Larger figure for poster
    fig.patch.set_facecolor('white')
    
    # Create a matrix showing valid actions organized by (operation, machine)
    action_matrix = np.zeros((env.num_operations, len(machine_list)))
    op_labels = []
    
    # Fill the action matrix
    for action_idx, (op_idx, machine) in enumerate(env.valid_action_pairs):
        machine_idx = machine_list.index(machine)
        if mask[action_idx]:
            action_matrix[op_idx, machine_idx] = 1
        else:
            action_matrix[op_idx, machine_idx] = 0  # Explicitly set illegal actions
    
    # Create operation labels
    for op_idx, (job_id, op_pos) in enumerate(env.operations):
        op_labels.append(f'J{job_id}-O{op_pos+1}')
    
    # Create grid visualization with binary colors (green for legal, red for illegal)
    # Use a custom colormap: 0 = red (illegal), 1 = green (legal)
    from matplotlib.colors import ListedColormap
    colors = ['red', 'green']  # 0 = illegal (red), 1 = legal (green)
    cmap = ListedColormap(colors)
    
    im = ax.imshow(action_matrix, cmap=cmap, aspect='auto', interpolation='nearest', vmin=0, vmax=1)
    ax.set_title('Action Mask: Operations vs Machines', fontsize=24, fontweight='bold', pad=20)
    ax.set_xlabel('Machine', fontsize=20, fontweight='bold')
    ax.set_ylabel('Operation', fontsize=20, fontweight='bold')
    
    # Set ticks and labels
    ax.set_xticks(range(len(machine_list)))
    ax.set_xticklabels(machine_list)
    ax.set_yticks(range(len(op_labels)))
    ax.set_yticklabels(op_labels, fontsize=14)
    
    # Add grid for better readability
    ax.set_xticks(np.arange(-0.5, len(machine_list), 1), minor=True)
    ax.set_yticks(np.arange(-0.5, len(op_labels), 1), minor=True)
    ax.grid(which="minor", color="black", linestyle='-', linewidth=1.5, alpha=0.4)
    
    # Add text annotations for actions
    for i in range(len(op_labels)):
        for j in range(len(machine_list)):
            if action_matrix[i, j] == 1:
                ax.text(j, i, '✓', ha='center', va='center', 
                       color='white', fontsize=18, fontweight='bold')
            else:
                ax.text(j, i, '✗', ha='center', va='center', 
                       color='white', fontsize=18, fontweight='bold')
    
    # Create custom legend showing legal and illegal actions
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='green', edgecolor='darkgreen', linewidth=2, label='Legal Actions'),
        Patch(facecolor='red', edgecolor='darkred', linewidth=2, label='Illegal Actions')
    ]
    
    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), 
             fontsize=18, frameon=True, fancybox=True, shadow=True)
    
    # Calculate statistics
    valid_actions = np.sum(mask)
    total_actions = len(mask)
    illegal_actions = total_actions - valid_actions
    ready_ops = np.sum([env.operation_status[i] == 'ready' for i in range(env.num_operations)])
    waiting_ops = np.sum([env.operation_status[i] == 'waiting' for i in range(env.num_operations)])
    done_ops = np.sum([env.operation_status[i] == 'done' for i in range(env.num_operations)])
    
    # Enlarged statistics text block positioned below the plot
    stats_text = f"""Action Mask Statistics:

• Total Actions: {total_actions}
• Legal Actions: {valid_actions} ({100*valid_actions/total_actions:.1f}%)
• Illegal Actions: {illegal_actions} ({100*illegal_actions/total_actions:.1f}%)

Operation Status:
• Ready: {ready_ops}/{env.num_operations}  • Waiting: {waiting_ops}/{env.num_operations}  • Done: {done_ops}/{env.num_operations}

Environment State:
• Current Time: {env.current_time:.2f}  • Arrived Jobs: {len(env.arrived_jobs)}/{len(env.job_ids)}
• Total Jobs: {len(env.job_ids)}  • Total Machines: {len(machine_list)}"""
    
    plt.tight_layout(rect=[0, 0, 0.85, 1])  # Full height for plot, reserve right space for legend only
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"Action mask visualization saved to {save_path}")
    
    plt.show()
    time.sleep(3)           # keep it open 3 seconds
    plt.close()
    
    # Print detailed action information
    print("\n--- Valid Action Details ---")
    print(f"Total actions: {total_actions}")
    print(f"Valid actions: {valid_actions}")
    print(f"Action validity rate: {100*valid_actions/total_actions:.1f}%")
    
    valid_count = 0
    for action_idx, (op_idx, machine) in enumerate(env.valid_action_pairs):
        if mask[action_idx]:
            job_id, op_pos = env.operations[op_idx]
            proc_time = env.jobs[job_id][op_pos]['proc_times'][machine]
            valid_count += 1
            print(f"  {valid_count}. J{job_id}-O{op_pos+1} on {machine} (proc_time={proc_time})")
            
    print(f"\nOperation Status Summary:")
    status_counts = {'waiting': 0, 'ready': 0, 'done': 0}
    for status in env.operation_status:
        status_counts[status] += 1
    for status, count in status_counts.items():
        print(f"  {status.capitalize()}: {count}")

def main(instance_file=None, timesteps=150000):
    """Main function that can be called with different instance files"""
    
    # Load instance data
    if instance_file and os.path.exists(instance_file):
        try:
            jobs_data, machine_list, eval_arrivals_dynamic = load_instance_from_file(instance_file)
        except Exception as e:
            print(f"Error loading instance file: {e}")
            print("Using default instance data...")
            jobs_data = DEFAULT_JOBS_DATA
            machine_list = DEFAULT_MACHINE_LIST
            eval_arrivals_dynamic = DEFAULT_ARRIVAL_TIMES
    else:
        if instance_file:
            print(f"Instance file {instance_file} not found. Using default instance data...")
        else:
            print("Using default instance data...")
        jobs_data = DEFAULT_JOBS_DATA
        machine_list = DEFAULT_MACHINE_LIST
        eval_arrivals_dynamic = DEFAULT_ARRIVAL_TIMES

    print("--- Job Structure ---")
    for job_id, operations in jobs_data.items():
        print(f"Job {job_id}: {len(operations)} operations, arrival: {eval_arrivals_dynamic.get(job_id, 'N/A')}")
        for i, op in enumerate(operations):
            print(f"  Operation {i+1}: can run on {list(op['proc_times'].keys())}")

    # Create job structure table figure
    plot_job_structure_table(jobs_data, machine_list, eval_arrivals_dynamic, 
                            save_path='job_structure_table.png')

    # --- Environment Details ---
    print("\n--- Environment Details ---")
    env = GraphDFJSPEnv(jobs_data, machine_list, eval_arrivals_dynamic)
    print(f"Observation space: {env.observation_space}")
    print(f"Action space size: {env.action_space.n}")
    mask = env.get_action_mask()
    print(f"Action mask (sum): {np.sum(mask)}")
    print(f"Valid action pairs: {len(env.valid_action_pairs)}")
    print(f"Action mask vector: {mask}")
    
    # Visualize the action mask
    visualize_action_mask(env, mask, jobs_data, machine_list, save_path='action_mask_visualization.png')
    
    eval_arrivals_static = {job_id: 0 for job_id in jobs_data.keys()}

    # --- Optimal and Heuristic Methods ---
    milp_makespan, milp_schedule = milp_scheduler(jobs_data, machine_list, eval_arrivals_dynamic)
    spt_makespan, spt_schedule = heuristic_spt_scheduler(jobs_data, machine_list, eval_arrivals_dynamic)

    # --- RL Training with Enhanced Methods ---
    static_model = train_agent(jobs_data, machine_list, eval_arrivals_static, "StaticTraining", timesteps)
    
    # Use enhanced training for dynamic model
    print("\n=== Using Enhanced Training for Dynamic Model ===")
    dynamic_model = train_enhanced_agent(jobs_data, machine_list, eval_arrivals_dynamic, "EnhancedDynamicTraining", timesteps)

    # --- RL Evaluations ---
    static_eval_static_makespan, static_eval_static_schedule = evaluate_agent(static_model, jobs_data, machine_list, eval_arrivals_static, "Static-Trained on Static-Eval")
    static_eval_dynamic_makespan, static_eval_dynamic_schedule = evaluate_agent(static_model, jobs_data, machine_list, eval_arrivals_dynamic, "Static-Trained on Dynamic-Eval")
    
    # Use multiple runs for the enhanced dynamic model to find the best result
    print("\n=== Enhanced Evaluation with Multiple Runs ===")
    dynamic_eval_dynamic_makespan, dynamic_eval_dynamic_schedule = evaluate_agent_multiple_runs(dynamic_model, jobs_data, machine_list, eval_arrivals_dynamic, "Enhanced-Dynamic-Trained", num_runs=15)

    # --- Final Comparison ---
    print("\n" + "="*50)
    print("FINAL RESULTS COMPARISON")
    print("="*50)
    print(f"MILP Optimal Makespan: {milp_makespan:.2f}")
    print(f"SPT Heuristic Makespan: {spt_makespan:.2f}")
    print(f"RL Static-Trained (Dynamic Eval): {static_eval_dynamic_makespan:.2f}")
    print(f"RL Dynamic-Trained (Dynamic Eval): {dynamic_eval_dynamic_makespan:.2f}")
    
    # --- Plotting Figure 1: Main Comparison ---
    plot_gantt_charts(
        figure_num=1,
        schedules=[milp_schedule, spt_schedule, static_eval_dynamic_schedule, dynamic_eval_dynamic_schedule],
        makespans=[milp_makespan, spt_makespan, static_eval_dynamic_makespan, dynamic_eval_dynamic_makespan],
        titles=['MILP Optimal', 'SPT Heuristic', 'RL (Static Training)', 'RL (Dynamic Training)'],
        machine_list=machine_list, 
        arrival_times=eval_arrivals_dynamic,
        save_path='figure1_main_comparison.png'
    )

    # --- Plotting Figure 2: Enhanced Static vs Dynamic RL Comparison with Poisson Distribution ---
    plot_rl_comparison_with_poisson(
        static_schedule=static_eval_dynamic_schedule,
        dynamic_schedule=dynamic_eval_dynamic_schedule, 
        static_makespan=static_eval_dynamic_makespan,
        dynamic_makespan=dynamic_eval_dynamic_makespan,
        machine_list=machine_list,
        arrival_times=eval_arrivals_dynamic,
        save_path='figure2_static_rl_generalization.png'
    )

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Dynamic FJSP Scheduler with RL')
    parser.add_argument('--instance', '-i', type=str, default=None,
                       help='Path to instance file (generated by possison.py)')
    parser.add_argument('--timesteps', '-t', type=int, default=150000,
                       help='Number of training timesteps (default: 150000)')
    parser.add_argument('--seed', '-s', type=int, default=42,
                       help='Random seed (default: 42)')
    
    args = parser.parse_args()
    
    # Set random seed
    random.seed(args.seed)
    np.random.seed(args.seed)
    
    # Run main function
    main(args.instance, args.timesteps)